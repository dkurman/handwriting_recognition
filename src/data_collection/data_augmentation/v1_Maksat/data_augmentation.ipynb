{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import random\n",
    "from random import randint\n",
    "input_folder = \"input_images\" # folder of classes folders with images\n",
    "output_folder = \"generated_images\" # results will be saven in this folder\n",
    "classes = 10 #number of classes \n",
    "augmentation_number = 10 # how many images will be created from each input image\n",
    "destination_size = (128,1024) # output image size\n",
    "word_height = int(destination_size[0]/2) # height of word in output image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING NOISES (SEVERAL VARIANTS)\n",
    "\n",
    "#variant 1\n",
    "def add_gaussian_noise(image_in, noise_sigma = 15):\n",
    "    noise_sigma = randint(1,noise_sigma)\n",
    "    temp_image = np.float64(np.copy(image_in))\n",
    "\n",
    "    h = temp_image.shape[0]\n",
    "    w = temp_image.shape[1]\n",
    "    noise = np.random.randn(h, w) * noise_sigma\n",
    "\n",
    "    noisy_image = np.zeros(temp_image.shape, np.float64)\n",
    "    if len(temp_image.shape) == 2:\n",
    "        noisy_image = temp_image + noise\n",
    "    else:\n",
    "        noisy_image[:,:,0] = temp_image[:,:,0] + noise\n",
    "        noisy_image[:,:,1] = temp_image[:,:,1] + noise\n",
    "        noisy_image[:,:,2] = temp_image[:,:,2] + noise\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "\n",
    "# variant 2\n",
    "def sp_noise(image,prob=0.05):\n",
    "    '''\n",
    "    Add salt and pepper noise to image\n",
    "    prob: Probability of the noise\n",
    "    '''\n",
    "    output = np.zeros(image.shape,np.uint8)\n",
    "    thres = 1 - prob \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            rdn = random.random()\n",
    "            if rdn < prob:\n",
    "                output[i][j] = 0\n",
    "            elif rdn > thres:\n",
    "                output[i][j] = 255\n",
    "            else:\n",
    "                output[i][j] = image[i][j]\n",
    "    return output\n",
    "\n",
    "# variant 3\n",
    "def numpy_noise(image, mean=0.0, std = 1.0):\n",
    "    # mean = 0.5  # some constant\n",
    "    # std = 1.0    # some constant (standard deviation)\n",
    "    noisy_img = image + np.random.normal(mean, std, image.shape)\n",
    "    return noise_img\n",
    "\n",
    "# КОД ДЛЯ ТЕСТА\n",
    "# image = cv2.imread('noises/image.jpg',0) # Only for grayscale image\n",
    "# noisy_img = add_gaussian_noise(image)\n",
    "# cv2.imwrite('noises/gaussian_image.jpg', noisy_img)\n",
    "# noisy_img = sp_noise(image)\n",
    "# cv2.imwrite('noises/sp_image.jpg', noisy_img)\n",
    "# noisy_img = numpy_noise(image)\n",
    "# cv2.imwrite('noises/numpy_image.jpg', noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect borders of the word in input image, and crop it\n",
    "def detect_word(img):\n",
    "    if len(img.shape)>2 and img.shape[2]>1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (destination_size[1], destination_size[0])) \n",
    "    #th = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    th = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    hist = np.average(th,axis=0)\n",
    "    rb = img.shape[1]\n",
    "    for i in range(len(hist)-1, 3, -1):\n",
    "        h=hist[i]\n",
    "        if hist[i]>252 or hist[i-1]>252 or hist[i-2]>252 :\n",
    "            rb = i\n",
    "        else:\n",
    "            break\n",
    "    crop_img = th[:,:rb]\n",
    "    new_width = int(crop_img.shape[1]*(word_height/crop_img.shape[0]))\n",
    "    detected_word = cv2.resize(crop_img, (new_width,word_height), interpolation = cv2.INTER_AREA)\n",
    "    return detected_word\n",
    "\n",
    "# put cropped image into template image with random position\n",
    "def random_position(small_image, big_image):\n",
    "    H,W = big_image.shape\n",
    "    h,w = small_image.shape\n",
    "    x_range = W-w\n",
    "    y_range = H-h\n",
    "    x_pos = randint(0,x_range)\n",
    "    y_pos = randint(0,y_range)\n",
    "    big_image[y_pos:y_pos+h,x_pos:x_pos+w] = small_image\n",
    "    return big_image\n",
    "\n",
    "# main function with generate image from single image\n",
    "def preproc_img(img):\n",
    "    crop_img = detect_word(img)   \n",
    "    new_img = np.ones((destination_size[0],destination_size[1]),dtype=np.uint8)*255\n",
    "    new_img = random_position(crop_img,new_img)\n",
    "    new_img = add_gaussian_noise(new_img,25)\n",
    "    return new_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение оригинального файла, аугментация и сохранение\n",
    "dataset = input_folder\n",
    "for c in range(0,classes):\n",
    "    class_dir = os.path.join(dataset,str(c))\n",
    "    all_files = glob.glob(class_dir+\"/*.jpg\")\n",
    "    \n",
    "    for j, full_path in enumerate(all_files):\n",
    "        file = os.path.basename(full_path)\n",
    "        img = cv2.imread(full_path)\n",
    "        for i in range(augmentation_number):\n",
    "            new_img = preproc_img(img)\n",
    "            # cv2.imshow(\"test\",new_img)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            # break\n",
    "            directory = output_folder+\"/\"+str(c)+\"/\"\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            cv2.imwrite(directory+file[:-4]+str(i)+file[-4:],new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение из готового датасета и разделение на train и test\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "test_portion = 0.15\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "dataset = output_folder\n",
    "for c in range(0,classes):\n",
    "    class_dir = os.path.join(dataset,str(c))\n",
    "    all_files = glob.glob(class_dir+\"/*.jpg\")\n",
    "    random.shuffle(all_files)\n",
    "    for j, full_path in enumerate(all_files):\n",
    "        file = os.path.basename(full_path)\n",
    "        img = cv2.imread(full_path)\n",
    "        img = cv2.resize(img,(int(img.shape[1]/2),int(img.shape[0]/2)))\n",
    "        if j<test_portion*len(all_files):\n",
    "            directory = test_dir+\"/\"+str(c)+\"/\"\n",
    "        else:\n",
    "            directory = train_dir+\"/\"+str(c)+\"/\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        cv2.imwrite(directory+file,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import augment_imgaug\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = \"input_images/8/823821.jpg\"\n",
    "aug_number = 5 \n",
    "OUTPUT_IMG_DIR = \"generated_images\"\n",
    "img = cv2.imread(full_path,cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, None, fx=0.5, fy=0.5,interpolation=cv2.INTER_CUBIC)\n",
    "new_img = augment_imgaug.preproc_img(img)\n",
    "cv2.imshow(\"input\",img)\n",
    "cv2.imshow(\"output\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "batch = augment_imgaug.compile_batch(img, aug_number)\n",
    "batch_aug = augment_imgaug.augment(batch)\n",
    "# save \n",
    "directory = OUTPUT_IMG_DIR+\"/\"\n",
    "augment_imgaug.save_batch(directory, batch_aug, aug_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
